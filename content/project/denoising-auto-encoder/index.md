---
title: Denoising Autoencoder
summary: Removing noise/dirt marks from scanned documents using Deep Autoencoder.
tags:
- Deep Learning
- Machine Learning
- Autoencoder
- Denoising
- Image processing
date: "2019-12-01"

# Optional external URL for project (replaces project detail page).
external_link: ""

image:
  caption:
  # focal_point: Smart

links:
- icon: twitter
  icon_pack: fab
  name: Follow
  url: https://twitter.com/pranaymns
- icon: linkedin
  icon_pack: fab
  name: Connect
  url: https://www.linkedin.com/in/pranaymodukuru/
url_code: "https://github.com/pranaymodukuru/DenoisingAutoencoder"
url_pdf: ""
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
# slides: example
---

Removing noise from images has been a reasonably tough task until the deep learning based auto encoders transformed the image processing field. I used a Deep Convolutional Autoencoder to remove coffe stains, footprints, marks resulting from folding or wrinkles from scanned office documents.

#### Please click on links below for more details
* [Project](https://github.com/pranaymodukuru/DenoisingAutoencoder)
* [Code](https://github.com/pranaymodukuru/DenoisingAutoencoder/blob/master/DenoisingAutoEncoder_NoisyOfficeData.ipynb)
